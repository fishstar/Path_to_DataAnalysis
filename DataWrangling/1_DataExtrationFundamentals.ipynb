{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Extraction Fundamentals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing CSV files \n",
    "\n",
    "### csv to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Please Please Me', 'Released': '22 March 1963', 'Label': 'Parlophone(UK)', 'UK Chart Position': '1', 'US Chart Position': '—', 'BPI Certification': 'Gold', 'RIAA Certification': 'Platinum'}\n"
     ]
    }
   ],
   "source": [
    "# Your task is to read the input DATAFILE line by line, and for the first 10 lines (not including the header)\n",
    "# split each line on \",\" and then for each line, create a dictionary\n",
    "# where the key is the header title of the field, and the value is the value of that field in the row.\n",
    "# The function parse_file should return a list of dictionaries,\n",
    "# each data line in the file being a single list entry.\n",
    "# Field names and values should not contain extra whitespace, like spaces or newline characters.\n",
    "# You can use the Python string method strip() to remove the extra whitespace.\n",
    "# You have to parse only the first 10 data lines in this exercise,\n",
    "# so the returned list should have 10 entries!\n",
    "import os\n",
    "\n",
    "DATADIR = \"data/\"\n",
    "DATAFILE = \"beatles-diskography.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    i = 0\n",
    "    with open(datafile, \"r\") as f:\n",
    "        for line in f:\n",
    "            values = [s.strip() for s in line.split(',')]\n",
    "            if i==0 :\n",
    "                head = values\n",
    "            elif i <= 10:\n",
    "                items = dict(zip(head, values))\n",
    "                data.append(items)\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "datafile = os.path.join(DATADIR, DATAFILE)\n",
    "d = parse_file(datafile)\n",
    "print(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all lines of csv file\n",
    "\n",
    "def parse_file2(datafile):\n",
    "    data = []\n",
    "    with open(datafile, \"r\") as f:\n",
    "        header = [s.strip() for s in f.readline().split(',')]\n",
    "        for line in f:\n",
    "            values = [s.strip() for s in line.split(',')]\n",
    "            data.append(dict(zip(header, values)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Title', 'Please Please Me'), ('Released', '22 March 1963'), ('Label', 'Parlophone(UK)'), ('UK Chart Position', '1'), ('US Chart Position', '—'), ('BPI Certification', 'Gold'), ('RIAA Certification', 'Platinum')])\n"
     ]
    }
   ],
   "source": [
    "# another way - using csv module\n",
    "import csv\n",
    "\n",
    "def parse_file3(datafile):\n",
    "    data = []\n",
    "    with open(datafile, \"r\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for line in r:\n",
    "            data.append(line)\n",
    "    return data\n",
    "\n",
    "d = parse_file3(datafile)\n",
    "print(d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to XLRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "datafile = \"data/2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "# parse excel to list of lists\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    \n",
    "    data = [[sheet.cell_value(row, col) \n",
    "                for col in range(sheet.ncols)]\n",
    "                   for row in range(sheet.nrows)]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = parse_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workbook = xlrd.open_workbook(datafile)\n",
    "sheet = workbook.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROWS, COLUMNS, and CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7296"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in the sheet\n",
    "sheet.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet.ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of data in cell (row 3, col 2)\n",
    "sheet.cell_type(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036.0886969999988"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value in cell (row 3, col 2)\n",
    "sheet.cell_value(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1411.7505669999982, 1403.4722870000019, 1395.053150000001]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a slice of values in column 3, from rows 1-3\n",
    "sheet.col_values(3, start_rowx=1, end_rowx=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of data in cell (row 1, col 0)\n",
    "sheet.cell_type(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 1, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert time to a Python datetime tuple\n",
    "exceltime = sheet.cell_value(1,0)\n",
    "xlrd.xldate_as_tuple(exceltime, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgcoast': 10976.933460679784,\n",
       " 'maxtime': (2013, 8, 13, 17, 0, 0),\n",
       " 'maxvalue': 18779.025510000003,\n",
       " 'mintime': (2013, 2, 3, 4, 0, 0),\n",
       " 'minvalue': 6602.1138989999818}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task is as follows:\n",
    "- read the provided Excel file\n",
    "- find and return the min, max and average values for the COAST region\n",
    "- find and return the time value for the min and max entries\n",
    "- the time values should be returned as Python tuples\n",
    "\n",
    "Please see the test function for the expected return format\n",
    "\"\"\"\n",
    "\n",
    "import xlrd\n",
    "import numpy\n",
    "\n",
    "datafile = \"data/2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    coast_values = sheet.col_values(1, start_rowx=1)\n",
    "    time_values = sheet.col_values(0, start_rowx=1)\n",
    "\n",
    "    maxvalue = np.max(coast_values)\n",
    "    minvalue = np.min(coast_values)\n",
    "    avgvalue = np.mean(coast_values)\n",
    "\n",
    "    maxtime = time_values[np.argmax(coast_values)]\n",
    "    mintime = time_values[np.argmin(coast_values)]\n",
    "    maxtime = xlrd.xldate_as_tuple(maxtime, 0)\n",
    "    mintime = xlrd.xldate_as_tuple(mintime, 0)\n",
    "    \n",
    "    data = {\n",
    "            'maxtime': maxtime,\n",
    "            'maxvalue': maxvalue,\n",
    "            'mintime': mintime,\n",
    "            'minvalue': minvalue,\n",
    "            'avgcoast': avgvalue\n",
    "    }\n",
    "    return data\n",
    "\n",
    "parse_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avgcoast': 10976.933460679751,\n",
      " 'maxtime': (2013, 8, 13, 17, 0, 0),\n",
      " 'maxvalue': 18779.025510000003,\n",
      " 'mintime': (2013, 2, 3, 4, 0, 0),\n",
      " 'minvalue': 6602.113898999982}\n"
     ]
    }
   ],
   "source": [
    "# solution without numpy\n",
    "\n",
    "import xlrd\n",
    "import pprint\n",
    "\n",
    "datafile = \"data/2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    coast_values = sheet.col_values(1, start_rowx=1)\n",
    "\n",
    "    maxvalue = max(coast_values)\n",
    "    minvalue = min(coast_values)\n",
    "    avgvalue = sum(coast_values) / len(coast_values)\n",
    "    \n",
    "    maxrow = coast_values.index(maxvalue) + 1\n",
    "    minrow = coast_values.index(minvalue) + 1\n",
    "\n",
    "    maxtime = sheet.cell_value(maxrow, 0)\n",
    "    mintime = sheet.cell_value(minrow, 0)\n",
    "    maxtime = xlrd.xldate_as_tuple(maxtime, 0)\n",
    "    mintime = xlrd.xldate_as_tuple(mintime, 0)\n",
    "    \n",
    "    data = {\n",
    "            'maxtime': maxtime,\n",
    "            'maxvalue': maxvalue,\n",
    "            'mintime': mintime,\n",
    "            'minvalue': minvalue,\n",
    "            'avgcoast': avgvalue\n",
    "    }\n",
    "    return data\n",
    "\n",
    "pprint.pprint(parse_file(datafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3ANirvana&fmt=json\n",
      "\n",
      "ARTIST:\n",
      "{\n",
      "    \"area\": {\n",
      "        \"id\": \"6a264f94-6ff1-30b1-9a81-41f7bfabd616\",\n",
      "        \"name\": \"Finland\",\n",
      "        \"sort-name\": \"Finland\"\n",
      "    },\n",
      "    \"country\": \"FI\",\n",
      "    \"disambiguation\": \"Early 1980's Finnish punk band\",\n",
      "    \"id\": \"85af0709-95db-4fbc-801a-120e9f4766d0\",\n",
      "    \"life-span\": {\n",
      "        \"ended\": null\n",
      "    },\n",
      "    \"name\": \"Nirvana\",\n",
      "    \"score\": \"100\",\n",
      "    \"sort-name\": \"Nirvana\",\n",
      "    \"tags\": [\n",
      "        {\n",
      "            \"count\": 1,\n",
      "            \"name\": \"punk\"\n",
      "        },\n",
      "        {\n",
      "            \"count\": 1,\n",
      "            \"name\": \"finland\"\n",
      "        }\n",
      "    ],\n",
      "    \"type\": \"Group\"\n",
      "}\n",
      "requesting http://musicbrainz.org/ws/2/artist/85af0709-95db-4fbc-801a-120e9f4766d0?inc=releases&fmt=json\n",
      "\n",
      "ONE RELEASE:\n",
      "{\n",
      "  \"barcode\": \"\",\n",
      "  \"country\": \"FI\",\n",
      "  \"date\": \"1980\",\n",
      "  \"disambiguation\": \"\",\n",
      "  \"id\": \"3e25396c-5c66-4609-8e47-37f250d323c7\",\n",
      "  \"packaging\": \"Cardboard/Paper Sleeve\",\n",
      "  \"packaging-id\": \"f7101ce3-0384-39ce-9fde-fbbd0044d35f\",\n",
      "  \"quality\": \"normal\",\n",
      "  \"release-events\": [\n",
      "    {\n",
      "      \"area\": {\n",
      "        \"disambiguation\": \"\",\n",
      "        \"id\": \"6a264f94-6ff1-30b1-9a81-41f7bfabd616\",\n",
      "        \"iso-3166-1-codes\": [\n",
      "          \"FI\"\n",
      "        ],\n",
      "        \"name\": \"Finland\",\n",
      "        \"sort-name\": \"Finland\"\n",
      "      },\n",
      "      \"date\": \"1980\"\n",
      "    }\n",
      "  ],\n",
      "  \"status\": \"Official\",\n",
      "  \"status-id\": \"4e304316-386d-3409-af2e-78857eec5cfe\",\n",
      "  \"text-representation\": {\n",
      "    \"language\": \"fin\",\n",
      "    \"script\": \"Latn\"\n",
      "  },\n",
      "  \"title\": \"Nirvana\"\n",
      "}\n",
      "\n",
      "ALL TITLES:\n",
      "Nirvana\n"
     ]
    }
   ],
   "source": [
    "# To experiment with this code freely you will have to run this code locally.\n",
    "# Take a look at the main() function for an example of how to use the code.\n",
    "# We have provided example json output in the other code editor tabs for you to\n",
    "# look at, but you will not be able to run any queries through our UI.\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "BASE_URL = \"http://musicbrainz.org/ws/2/\"\n",
    "ARTIST_URL = BASE_URL + \"artist/\"\n",
    "\n",
    "# query parameters are given to the requests.get function as a dictionary; this\n",
    "# variable contains some starter parameters.\n",
    "query_type = {  \"simple\": {},\n",
    "                \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "                \"aliases\": {\"inc\": \"aliases\"},\n",
    "                \"releases\": {\"inc\": \"releases\"}}\n",
    "\n",
    "\n",
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    # This is the main function for making queries to the musicbrainz API.\n",
    "    # A json document should be returned by the query.\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "    print(\"requesting\", r.url)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def query_by_name(url, params, name):\n",
    "    # This adds an artist name to the query parameters before making\n",
    "    # an API call to the function above.\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)\n",
    "\n",
    "\n",
    "def pretty_print(data, indent=4):\n",
    "    # After we get our output, we can format it to be more readable\n",
    "    # by using this function.\n",
    "    if type(data) == dict:\n",
    "        print(json.dumps(data, indent=indent, sort_keys=True))\n",
    "    else:\n",
    "        print(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Nirvana\")\n",
    "#    pretty_print(results)\n",
    "\n",
    "artist_id = results[\"artists\"][1][\"id\"]\n",
    "print(\"\\nARTIST:\")\n",
    "pretty_print(results[\"artists\"][1])\n",
    "\n",
    "artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "releases = artist_data[\"releases\"]\n",
    "print(\"\\nONE RELEASE:\")\n",
    "pretty_print(releases[0], indent=2)\n",
    "release_titles = [r[\"title\"] for r in releases]\n",
    "\n",
    "print(\"\\nALL TITLES:\")\n",
    "for t in release_titles:\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz : How many bands named \"first aid kit\"?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AFIRST+AID+KIT&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"FIRST AID KIT\")\n",
    "len(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Begin-area name for Queen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AQueen&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'London'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Queen\")\n",
    "results['artists'][2]['begin-area']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
