{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Using Our Blueprint\n",
    "\n",
    "[OpenStreetMap data](https://mapzen.com/data/metro-extracts/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4: 1\n",
      "Ardsley: 1\n",
      "Ave: 2\n",
      "Ave.: 2\n",
      "Avenue: 30\n",
      "Blvd: 4\n",
      "Boulevard: 34\n",
      "Dr: 2\n",
      "Drive: 27\n",
      "Lane: 4\n",
      "Place: 16\n",
      "Road: 56\n",
      "St: 2\n",
      "Street: 48\n",
      "Way: 2\n"
     ]
    }
   ],
   "source": [
    "# get different types of street names\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "osm_file = open(\"data/charlotte.osm\", \"r\")\n",
    "\n",
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "street_types = defaultdict(int)\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        street_types[street_type] += 1\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print(\"%s: %d\" % (k, v))\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit():\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        if is_street_name(elem):\n",
    "            audit_street_type(street_types, elem.attrib['v'])    \n",
    "    print_sorted_dict(street_types)    \n",
    "\n",
    "\n",
    "\n",
    "audit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\"\"\"\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'data/autos.csv'\n",
    "OUTPUT_GOOD = 'data/autos-valid.csv'\n",
    "OUTPUT_BAD = 'data/FIXME-autos.csv'\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "\n",
    "    data_good = []\n",
    "    data_bad = []\n",
    "    \n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        \n",
    "        for row in reader:\n",
    "            # validate URI value\n",
    "            if row['URI'].find('dbpedia.org') < 0:\n",
    "                continue\n",
    "                \n",
    "            ps_year = row['productionStartYear'][:4]\n",
    "            try:  # use try/except to filter valid items\n",
    "                ps_year = int(ps_year)\n",
    "                row['productionStartYear'] = ps_year\n",
    "                if (ps_year >= 1886) and (ps_year <= 2014):\n",
    "                    data_good.append(row)\n",
    "                else:\n",
    "                    data_bad.append(row)\n",
    "            except ValueError:  # non-numeric strings caught by exception\n",
    "                if ps_year == 'Null':\n",
    "                    data_bad.append(row)\n",
    "                \n",
    "\n",
    "    with open(output_good, \"w\") as good:\n",
    "        writer = csv.DictWriter(good, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_good:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    with open(output_bad, \"w\") as bad:\n",
    "        writer = csv.DictWriter(bad, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_bad:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "\n",
    "process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
