{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data\n",
    "\n",
    "## Merging DataFrames\n",
    "### Merging on a specific column\n",
    "This exercise follows on the last one with the DataFrames revenue and managers for your company. You expect your company to grow and, eventually, to operate in cities with the same name on different states. As such, you decide that every branch should have a numerical branch identifier. Thus, you add a branch_id column to both DataFrames. Moreover, new cities have been added to both the revenue and managers DataFrames as well. pandas has been imported as pd and both DataFrames are available in your namespace.\n",
    "\n",
    "At present, there should be a 1-to-1 relationship between the city and branch_id fields. In that case, the result of a merge on the city columns ought to give you the same output as a merge on the branch_id columns. Do they? Can you spot an ambiguity in one of the DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id         city  revenue\n",
      "0         10       Austin      100\n",
      "1         20       Denver       83\n",
      "2         30  Springfield        4\n",
      "3         47    Mendocino      200 \n",
      "\n",
      "   branch_id         city   manager\n",
      "0         10       Austin  Charlers\n",
      "1         20       Denver      Joel\n",
      "2         47    Mendocino     Brett\n",
      "3         31  Springfield     Sally\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revenue = pd.DataFrame([[10, 'Austin', 100],\n",
    "                       [20, 'Denver', 83],\n",
    "                       [30, 'Springfield', 4],\n",
    "                       [47, 'Mendocino', 200]], \n",
    "                      columns=['branch_id', 'city', 'revenue'])\n",
    "managers = pd.DataFrame([[10, 'Austin', 'Charlers'],\n",
    "                       [20, 'Denver', 'Joel'],\n",
    "                       [47, 'Mendocino', 'Brett'],\n",
    "                       [31, 'Springfield', 'Sally']],\n",
    "                       columns=['branch_id', 'city', 'manager'])\n",
    "print(revenue, '\\n')\n",
    "print(managers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id_x         city  revenue  branch_id_y   manager\n",
      "0           10       Austin      100           10  Charlers\n",
      "1           20       Denver       83           20      Joel\n",
      "2           30  Springfield        4           31     Sally\n",
      "3           47    Mendocino      200           47     Brett\n"
     ]
    }
   ],
   "source": [
    "# Merge revenue with managers on 'city': merge_by_city\n",
    "merge_by_city = pd.merge(revenue, managers, on='city')\n",
    "\n",
    "# Print merge_by_city\n",
    "print(merge_by_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id     city_x  revenue     city_y   manager\n",
      "0         10     Austin      100     Austin  Charlers\n",
      "1         20     Denver       83     Denver      Joel\n",
      "2         47  Mendocino      200  Mendocino     Brett\n"
     ]
    }
   ],
   "source": [
    "# Merge revenue with managers on 'branch_id': merge_by_id\n",
    "merge_by_id = pd.merge(revenue, managers, on='branch_id')\n",
    "\n",
    "# Print merge_by_id\n",
    "print(merge_by_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on multiple columns\n",
    "\n",
    "Another strategy to disambiguate cities with identical names is to add information on the states in which the cities are located. To this end, you add a column called state to both DataFrames from the preceding exercises. Again, pandas has been pre-imported as pd and the revenue and managers DataFrames are in your namespace.\n",
    "\n",
    "Your goal in this exercise is to use pd.merge() to merge DataFrames using multiple columns (using 'branch_id', 'city', and 'state' in this case).\n",
    "\n",
    "Are you able to match all your company's branches correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id       city  revenue state   manager\n",
      "0         10     Austin      100    TX  Charlers\n",
      "1         20     Denver       83    CO      Joel\n",
      "2         47  Mendocino      200    CA     Brett\n"
     ]
    }
   ],
   "source": [
    "# Add 'state' column to revenue: revenue['state']\n",
    "revenue['state'] = ['TX','CO','IL','CA']\n",
    "\n",
    "# Add 'state' column to managers: managers['state']\n",
    "managers['state'] = ['TX','CO','CA','MO']\n",
    "\n",
    "# Merge revenue & managers on 'branch_id', 'city', & 'state': combined\n",
    "combined = pd.merge(revenue, managers, on=['branch_id', 'city', 'state'])\n",
    "\n",
    "# Print combined\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on columns with non-matching labels\n",
    "You continue working with the revenue & managers DataFrames from before. This time, someone has changed the field name 'city' to 'branch' in the managers table. Now, when you attempt to merge DataFrames, an exception is thrown:\n",
    "```\n",
    ">>> pd.merge(revenue, managers, on='city')\n",
    "Traceback (most recent call last):\n",
    "    ... <text deleted> ...\n",
    "    pd.merge(revenue, managers, on='city')\n",
    "    ... <text deleted> ...\n",
    "KeyError: 'city'\n",
    "```\n",
    "\n",
    "Given this, it will take a bit more work for you to join or merge on the city/branch name. You have to specify the left_on and right_on parameters in the call to pd.merge().\n",
    "\n",
    "As before, pandas has been pre-imported as pd and the revenue and managers DataFrames are in your namespace. They have been printed in the IPython Shell so you can examine the columns prior to merging.\n",
    "\n",
    "Are you able to merge better than in the last exercise? How should the rows with Springfield be handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id         city  revenue state\n",
      "0         10       Austin      100    TX\n",
      "1         20       Denver       83    CO\n",
      "2         30  Springfield        4    IL\n",
      "3         47    Mendocino      200    CA \n",
      "\n",
      "        branch  branch_id   manager state\n",
      "0       Austin         10  Charlers    TX\n",
      "1       Denver         20      Joel    CO\n",
      "2    Mendocino         47     Brett    CA\n",
      "3  Springfield         31     Sally    MO\n"
     ]
    }
   ],
   "source": [
    "revenue = pd.DataFrame([[10, 'Austin', 100, 'TX'],\n",
    "                       [20, 'Denver', 83, 'CO'],\n",
    "                       [30, 'Springfield', 4, 'IL'],\n",
    "                       [47, 'Mendocino', 200, 'CA']],\n",
    "                       columns = ['branch_id', 'city', 'revenue', 'state'])\n",
    "managers = pd.DataFrame([['Austin', 10, 'Charlers', 'TX'],\n",
    "                       ['Denver', 20, 'Joel', 'CO'],\n",
    "                       ['Mendocino', 47, 'Brett', 'CA'],\n",
    "                       ['Springfield', 31, 'Sally', 'MO']],\n",
    "                       columns = ['branch', 'branch_id', 'manager', 'state'])\n",
    "print(revenue, '\\n')\n",
    "print(managers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id_x         city  revenue state_x       branch  branch_id_y  \\\n",
      "0           10       Austin      100      TX       Austin           10   \n",
      "1           20       Denver       83      CO       Denver           20   \n",
      "2           30  Springfield        4      IL  Springfield           31   \n",
      "3           47    Mendocino      200      CA    Mendocino           47   \n",
      "\n",
      "    manager state_y  \n",
      "0  Charlers      TX  \n",
      "1      Joel      CO  \n",
      "2     Sally      MO  \n",
      "3     Brett      CA  \n"
     ]
    }
   ],
   "source": [
    "# Merge revenue & managers on 'city' & 'branch': combined\n",
    "combined = pd.merge(revenue, managers, left_on='city', right_on='branch')\n",
    "\n",
    "# Print combined\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining DataFrames\n",
    "### Left & right merging on multiple columns\n",
    "You now have, in addition to the revenue and managers DataFrames from prior exercises, a DataFrame sales that summarizes units sold from specific branches (identified by city and state but not branch_id).\n",
    "\n",
    "Once again, the managers DataFrame uses the label branch in place of city as in the other two DataFrames. Your task here is to employ left and right merges to preserve data and identify where data is missing.\n",
    "\n",
    "By merging revenue and sales with a right merge, you can identify the missing revenue values. Here, you don't need to specify left_on or right_on because the columns to merge on have matching labels.\n",
    "\n",
    "By merging sales and managers with a left merge, you can identify the missing manager. Here, the columns to merge on have conflicting labels, so you must specify left_on and right_on. In both cases, you're looking to figure out how to connect the fields in rows containing Springfield.\n",
    "\n",
    "pandas has been imported as pd and the three DataFrames revenue, managers, and sales have been pre-loaded. They have been printed for you to explore in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.DataFrame([['Mendocino', 'CA', 1],\n",
    "                       ['Denver', 'CO', 4],\n",
    "                       ['Austin', 'TX', 2],\n",
    "                       ['Springfield', 'MO', 5],\n",
    "                       ['Springfield', 'IL', 1]],\n",
    "                    columns = ['city', 'state', 'units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id         city  revenue state  units\n",
      "0       10.0       Austin    100.0    TX      2\n",
      "1       20.0       Denver     83.0    CO      4\n",
      "2       30.0  Springfield      4.0    IL      1\n",
      "3       47.0    Mendocino    200.0    CA      1\n",
      "4        NaN  Springfield      NaN    MO      5\n"
     ]
    }
   ],
   "source": [
    "# Merge revenue and sales: revenue_and_sales\n",
    "revenue_and_sales = pd.merge(revenue, sales, how='right', on=['city', 'state'])\n",
    "\n",
    "# Print revenue_and_sales\n",
    "print(revenue_and_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city state  units       branch  branch_id   manager\n",
      "0    Mendocino    CA      1    Mendocino       47.0     Brett\n",
      "1       Denver    CO      4       Denver       20.0      Joel\n",
      "2       Austin    TX      2       Austin       10.0  Charlers\n",
      "3  Springfield    MO      5  Springfield       31.0     Sally\n",
      "4  Springfield    IL      1          NaN        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Merge sales and managers: sales_and_managers\n",
    "sales_and_managers = pd.merge(sales, managers, how='left', left_on=['city', 'state'], right_on=['branch', 'state'])\n",
    "\n",
    "# Print sales_and_managers\n",
    "print(sales_and_managers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging DataFrames with outer join\n",
    "This exercise picks up where the previous one left off. The DataFrames revenue, managers, and sales are pre-loaded into your namespace (and, of course, pandas is imported as pd). Moreover, the merged DataFrames revenue_and_sales and sales_and_managers have been pre-computed exactly as you did in the previous exercise.\n",
    "\n",
    "The merged DataFrames contain enough information to construct a DataFrame with 5 rows with all known information correctly aligned and each branch listed only once. You will try to merge the merged DataFrames on all matching keys (which computes an inner join by default). You can compare the result to an outer join and also to an outer join with restricted subset of columns as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        city state  units     branch  branch_id   manager  revenue\n",
      "0  Mendocino    CA      1  Mendocino       47.0     Brett    200.0\n",
      "1     Denver    CO      4     Denver       20.0      Joel     83.0\n",
      "2     Austin    TX      2     Austin       10.0  Charlers    100.0\n"
     ]
    }
   ],
   "source": [
    "# Perform the first merge: merge_default\n",
    "merge_default = pd.merge(sales_and_managers, revenue_and_sales)\n",
    "\n",
    "# Print merge_default\n",
    "print(merge_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city state  units       branch  branch_id   manager  revenue\n",
      "0    Mendocino    CA      1    Mendocino       47.0     Brett    200.0\n",
      "1       Denver    CO      4       Denver       20.0      Joel     83.0\n",
      "2       Austin    TX      2       Austin       10.0  Charlers    100.0\n",
      "3  Springfield    MO      5  Springfield       31.0     Sally      NaN\n",
      "4  Springfield    IL      1          NaN        NaN       NaN      NaN\n",
      "5  Springfield    IL      1          NaN       30.0       NaN      4.0\n",
      "6  Springfield    MO      5          NaN        NaN       NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Perform the second merge: merge_outer\n",
    "merge_outer = pd.merge(sales_and_managers, revenue_and_sales, how='outer')\n",
    "\n",
    "# Print merge_outer\n",
    "print(merge_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city state  units_x       branch  branch_id_x   manager  \\\n",
      "0    Mendocino    CA        1    Mendocino         47.0     Brett   \n",
      "1       Denver    CO        4       Denver         20.0      Joel   \n",
      "2       Austin    TX        2       Austin         10.0  Charlers   \n",
      "3  Springfield    MO        5  Springfield         31.0     Sally   \n",
      "4  Springfield    IL        1          NaN          NaN       NaN   \n",
      "\n",
      "   branch_id_y  revenue  units_y  \n",
      "0         47.0    200.0        1  \n",
      "1         20.0     83.0        4  \n",
      "2         10.0    100.0        2  \n",
      "3          NaN      NaN        5  \n",
      "4         30.0      4.0        1  \n"
     ]
    }
   ],
   "source": [
    "# Perform the third merge: merge_outer_on\n",
    "merge_outer_on = pd.merge(sales_and_managers, revenue_and_sales, how='outer', on=['city','state'])\n",
    "\n",
    "# Print merge_outer_on\n",
    "print(merge_outer_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered merges\n",
    "### Using merge_ordered()\n",
    "This exercise uses pre-loaded DataFrames austin and houston that contain weather data from the cities Austin and Houston respectively. They have been printed in the IPython Shell for you to examine.\n",
    "\n",
    "Weather conditions were recorded on separate days and you need to merge these two DataFrames together such that the dates are ordered. To do this, you'll use pd.merge_ordered(). After you're done, note the order of the rows before and after merging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date ratings\n",
      "0 2016-01-01  Cloudy\n",
      "1 2016-02-08  Cloudy\n",
      "2 2016-01-17   Sunny\n"
     ]
    }
   ],
   "source": [
    "austin = pd.DataFrame([[pd.to_datetime('2016-01-01 00:00:00'), 'Cloudy'],\n",
    "       [pd.to_datetime('2016-02-08 00:00:00'), 'Cloudy'],\n",
    "       [pd.to_datetime('2016-01-17 00:00:00'), 'Sunny']],\n",
    "                     columns = ['date', 'ratings'])\n",
    "print(austin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date ratings\n",
      "0 2016-01-04   Rainy\n",
      "1 2016-01-01  Cloudy\n",
      "2 2016-03-01   Sunny\n"
     ]
    }
   ],
   "source": [
    "houston = pd.DataFrame([[pd.to_datetime('2016-01-04 00:00:00'), 'Rainy'],\n",
    "       [pd.to_datetime('2016-01-01 00:00:00'), 'Cloudy'],\n",
    "       [pd.to_datetime('2016-03-01 00:00:00'), 'Sunny']],\n",
    "                      columns = ['date', 'ratings'])\n",
    "print(houston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date ratings\n",
      "0 2016-01-01  Cloudy\n",
      "1 2016-01-04   Rainy\n",
      "2 2016-01-17   Sunny\n",
      "3 2016-02-08  Cloudy\n",
      "4 2016-03-01   Sunny\n"
     ]
    }
   ],
   "source": [
    "# Perform the first ordered merge: tx_weather\n",
    "tx_weather = pd.merge_ordered(austin, houston)\n",
    "\n",
    "# Print tx_weather\n",
    "print(tx_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date ratings_aus ratings_hus\n",
      "0 2016-01-01      Cloudy      Cloudy\n",
      "1 2016-01-04         NaN       Rainy\n",
      "2 2016-01-17       Sunny         NaN\n",
      "3 2016-02-08      Cloudy         NaN\n",
      "4 2016-03-01         NaN       Sunny\n"
     ]
    }
   ],
   "source": [
    "# Perform the second ordered merge: tx_weather_suff\n",
    "tx_weather_suff = pd.merge_ordered(austin, houston, on='date', suffixes=['_aus','_hus'])\n",
    "\n",
    "# Print tx_weather_suff\n",
    "print(tx_weather_suff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date ratings_aus ratings_hus\n",
      "0 2016-01-01      Cloudy      Cloudy\n",
      "1 2016-01-04      Cloudy       Rainy\n",
      "2 2016-01-17       Sunny       Rainy\n",
      "3 2016-02-08      Cloudy       Rainy\n",
      "4 2016-03-01      Cloudy       Sunny\n"
     ]
    }
   ],
   "source": [
    "# Perform the third ordered merge: tx_weather_ffill\n",
    "tx_weather_ffill = pd.merge_ordered(austin, houston, on='date', suffixes=['_aus','_hus'], fill_method='ffill')\n",
    "\n",
    "# Print tx_weather_ffill\n",
    "print(tx_weather_ffill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using merge_asof()\n",
    "Similar to pd.merge_ordered(), the pd.merge_asof() function will also merge values in order using the on column, but for each row in the left DataFrame, only rows from the right DataFrame whose 'on' column values are less than the left value will be kept.\n",
    "\n",
    "This function can be use to align disparate datetime frequencies without having to first resample.\n",
    "\n",
    "Here, you'll merge monthly oil prices (US dollars) into a full automobile fuel efficiency dataset. The oil and automobile DataFrames have been pre-loaded as oil and auto. The first 5 rows of each have been printed in the IPython Shell for you to explore.\n",
    "\n",
    "These datasets will align such that the first price of the year will be broadcast into the rows of the automobiles DataFrame. This is considered correct since by the start of any given year, most automobiles for that year will have already been manufactured.\n",
    "\n",
    "You'll then inspect the merged DataFrame, resample by year and compute the mean 'Price' and 'mpg'. You should be able to see a trend in these two columns, that you can confirm by computing the Pearson correlation between resampled 'Price' and 'mpg'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl  displ   hp  weight  accel         yr origin  \\\n",
       "0  18.0    8  307.0  130    3504   12.0 1970-01-01     US   \n",
       "1  15.0    8  350.0  165    3693   11.5 1970-01-01     US   \n",
       "2  18.0    8  318.0  150    3436   11.0 1970-01-01     US   \n",
       "3  16.0    8  304.0  150    3433   12.0 1970-01-01     US   \n",
       "4  17.0    8  302.0  140    3449   10.5 1970-01-01     US   \n",
       "\n",
       "                        name  \n",
       "0  chevrolet chevelle malibu  \n",
       "1          buick skylark 320  \n",
       "2         plymouth satellite  \n",
       "3              amc rebel sst  \n",
       "4                ford torino  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('auto.csv')\n",
    "auto.yr = pd.to_datetime(auto.yr)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-02-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-03-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-04-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-05-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Price\n",
       "0 1970-01-01   3.35\n",
       "1 1970-02-01   3.35\n",
       "2 1970-03-01   3.35\n",
       "3 1970-04-01   3.35\n",
       "4 1970-05-01   3.35"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil = pd.read_csv('oil.csv')\n",
    "oil.Date = pd.to_datetime(oil.Date)\n",
    "oil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mpg  cyl  displ  hp  weight  accel         yr  origin             name  \\\n",
      "387  27.0    4  140.0  86    2790   15.6 1982-01-01      US  ford mustang gl   \n",
      "388  44.0    4   97.0  52    2130   24.6 1982-01-01  Europe        vw pickup   \n",
      "389  32.0    4  135.0  84    2295   11.6 1982-01-01      US    dodge rampage   \n",
      "390  28.0    4  120.0  79    2625   18.6 1982-01-01      US      ford ranger   \n",
      "391  31.0    4  119.0  82    2720   19.4 1982-01-01      US       chevy s-10   \n",
      "\n",
      "          Date  Price  \n",
      "387 1982-01-01  33.85  \n",
      "388 1982-01-01  33.85  \n",
      "389 1982-01-01  33.85  \n",
      "390 1982-01-01  33.85  \n",
      "391 1982-01-01  33.85  \n"
     ]
    }
   ],
   "source": [
    "# Merge automobile and oil: merged\n",
    "merged = pd.merge_asof(auto, oil, left_on='yr', right_on='Date')\n",
    "\n",
    "# Print the tail of merged\n",
    "print(merged.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mpg  Price\n",
      "Date                        \n",
      "1970-12-31  17.689655   3.35\n",
      "1971-12-31  21.111111   3.56\n",
      "1972-12-31  18.714286   3.56\n",
      "1973-12-31  17.100000   3.56\n",
      "1974-12-31  22.769231  10.11\n",
      "1975-12-31  20.266667  11.16\n",
      "1976-12-31  21.573529  11.16\n",
      "1977-12-31  23.375000  13.90\n",
      "1978-12-31  24.061111  14.85\n",
      "1979-12-31  25.093103  14.85\n",
      "1980-12-31  33.803704  32.50\n",
      "1981-12-31  30.185714  38.00\n",
      "1982-12-31  32.000000  33.85\n",
      "            mpg     Price\n",
      "mpg    1.000000  0.948677\n",
      "Price  0.948677  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Resample merged: yearly\n",
    "yearly = merged.resample('A', on='Date')[['mpg', 'Price']].mean()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# print yearly.corr()\n",
    "print(yearly.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
