{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in More Complex Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing  XLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "\n",
    "tree = ET.parse('data/exampleResearchArticle.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ui\n",
      "ji\n",
      "fm\n",
      "bdy\n",
      "bm\n"
     ]
    }
   ],
   "source": [
    "# Children of root\n",
    "for child in root:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Standardization of the functional syndesmosis widening by dynamic U.S examination\n"
     ]
    }
   ],
   "source": [
    "title = root.find('./fm/bibl/title')\n",
    "title_text = \"\"\n",
    "for p in title:\n",
    "    title_text += p.text\n",
    "print(\"Title: \", title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omer@extremegate.com\n",
      "mcarmont@hotmail.com\n",
      "laver17@gmail.com\n",
      "nyska@internet-zahav.net\n",
      "kammarh@gmail.com\n",
      "gideon.mann.md@gmail.com\n",
      "barns.nz@gmail.com\n",
      "eukots@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# Author email addresses\n",
    "for a in root.findall('./fm/bibl/aug/au'):\n",
    "    email = a.find('email')\n",
    "    if email is not None:\n",
    "        print(email.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'email': 'omer@extremegate.com', 'fnm': 'Omer', 'snm': 'Mei-Dan'},\n",
       " {'email': 'mcarmont@hotmail.com', 'fnm': 'Mike', 'snm': 'Carmont'},\n",
       " {'email': 'laver17@gmail.com', 'fnm': 'Lior', 'snm': 'Laver'},\n",
       " {'email': 'nyska@internet-zahav.net', 'fnm': 'Meir', 'snm': 'Nyska'},\n",
       " {'email': 'kammarh@gmail.com', 'fnm': 'Hagay', 'snm': 'Kammar'},\n",
       " {'email': 'gideon.mann.md@gmail.com', 'fnm': 'Gideon', 'snm': 'Mann'},\n",
       " {'email': 'barns.nz@gmail.com', 'fnm': 'Barnaby', 'snm': 'Clarck'},\n",
       " {'email': 'eukots@gmail.com', 'fnm': 'Eugene', 'snm': 'Kots'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your task here is to extract data from xml on authors of an article\n",
    "# and add it to a list, one item for an author.\n",
    "# See the provided data structure for the expected format.\n",
    "# The tags for first name, surname and email should map directly\n",
    "# to the dictionary keys\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "article_file = \"data/exampleResearchArticle.xml\"\n",
    "\n",
    "\n",
    "def get_root(fname):\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "def get_authors(root):\n",
    "    authors = []\n",
    "    for author in root.findall('./fm/bibl/aug/au'):\n",
    "        data = {\n",
    "                \"fnm\": None,\n",
    "                \"snm\": None,\n",
    "                \"email\": None\n",
    "        }\n",
    "        \n",
    "        for tag in ['fnm', 'snm', 'email']:\n",
    "            tagvalue = author.find(tag)\n",
    "            if tagvalue is not None:\n",
    "                data[tag] = tagvalue.text\n",
    "\n",
    "        authors.append(data)\n",
    "\n",
    "    return authors\n",
    "\n",
    "\n",
    "root = get_root(article_file)\n",
    "data = get_authors(root)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handing Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'email': 'omer@extremegate.com',\n",
       "  'fnm': 'Omer',\n",
       "  'insr': ['I1'],\n",
       "  'snm': 'Mei-Dan'},\n",
       " {'email': 'mcarmont@hotmail.com',\n",
       "  'fnm': 'Mike',\n",
       "  'insr': ['I2'],\n",
       "  'snm': 'Carmont'},\n",
       " {'email': 'laver17@gmail.com',\n",
       "  'fnm': 'Lior',\n",
       "  'insr': ['I3', 'I4'],\n",
       "  'snm': 'Laver'},\n",
       " {'email': 'nyska@internet-zahav.net',\n",
       "  'fnm': 'Meir',\n",
       "  'insr': ['I3'],\n",
       "  'snm': 'Nyska'},\n",
       " {'email': 'kammarh@gmail.com',\n",
       "  'fnm': 'Hagay',\n",
       "  'insr': ['I8'],\n",
       "  'snm': 'Kammar'},\n",
       " {'email': 'gideon.mann.md@gmail.com',\n",
       "  'fnm': 'Gideon',\n",
       "  'insr': ['I3', 'I5'],\n",
       "  'snm': 'Mann'},\n",
       " {'email': 'barns.nz@gmail.com',\n",
       "  'fnm': 'Barnaby',\n",
       "  'insr': ['I6'],\n",
       "  'snm': 'Clarck'},\n",
       " {'email': 'eukots@gmail.com', 'fnm': 'Eugene', 'insr': ['I7'], 'snm': 'Kots'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your task here is to extract data from xml on authors of an article\n",
    "# and add it to a list, one item for an author.\n",
    "# See the provided data structure for the expected format.\n",
    "# The tags for first name, surname and email should map directly\n",
    "# to the dictionary keys, but you have to extract the attributes from the \"insr\" tag\n",
    "# and add them to the list for the dictionary key \"insr\"\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "article_file = \"data/exampleResearchArticle.xml\"\n",
    "\n",
    "\n",
    "def get_root(fname):\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "def get_authors(root):\n",
    "    authors = []\n",
    "    for author in root.findall('./fm/bibl/aug/au'):\n",
    "        data = {\n",
    "                \"fnm\": author.find('fnm').text,\n",
    "                \"snm\": author.find('snm').text,\n",
    "                \"email\": author.find('email').text,\n",
    "                \"insr\": [ x.attrib['iid'] for x in author.findall('insr')]\n",
    "        }\n",
    "\n",
    "        authors.append(data)\n",
    "\n",
    "    return authors\n",
    "\n",
    "root = get_root(article_file)\n",
    "data = get_authors(root)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carriers:\n",
      "All\n",
      "AllUS\n",
      "AllForeign\n",
      "AS\n",
      "G4\n",
      "AA\n",
      "5Y\n",
      "DL\n",
      "MQ\n",
      "EV\n",
      "F9\n",
      "HA\n",
      "B6\n",
      "OO\n",
      "WN\n",
      "NK\n",
      "UA\n",
      "VX\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def options(soup, id):\n",
    "    option_values = []\n",
    "    carrier_list = soup.find(id=id)\n",
    "    for option in carrier_list.find_all('option'):\n",
    "        option_values.append(option['value'])\n",
    "    return option_values\n",
    "\n",
    "def print_list(label, codes):\n",
    "    print('\\n%s:' % label)\n",
    "    for c in codes:\n",
    "        print(c)\n",
    "        \n",
    "soup = BeautifulSoup(open('data/airport.html'), 'lxml')\n",
    "\n",
    "codes = options(soup, 'CarrierList')\n",
    "print_list('Carriers', codes)\n",
    "\n",
    "codes = options(soup, 'AirportList')\n",
    "#print_list('Airports', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Please note that the function 'make_request' is provided for your reference only.\n",
    "# You will not be able to to actually use it from within the Udacity web UI.\n",
    "# Your task is to process the HTML using BeautifulSoup, extract the hidden\n",
    "# form field values for \"__EVENTVALIDATION\" and \"__VIEWSTATE\" and set the appropriate\n",
    "# values in the data dictionary.\n",
    "# All your changes should be in the 'extract_data' function\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "html_page = 'data/airport.html'\n",
    "\n",
    "\n",
    "def extract_data(page):\n",
    "    data = {\"eventvalidation\": \"\",\n",
    "            \"viewstate\": \"\"}\n",
    "    with open(page, \"r\") as html:\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        data[\"eventvalidation\"] = soup.find(id=\"__EVENTVALIDATION\")['value']\n",
    "        data[\"viewstate\"] = soup.find(id=\"__VIEWSTATE\")['value']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def make_request(data):\n",
    "    eventvalidation = data[\"eventvalidation\"]\n",
    "    viewstate = data[\"viewstate\"]\n",
    "\n",
    "    r = requests.post(\"http://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "                    data={'AirportList': \"BOS\",\n",
    "                          'CarrierList': \"VX\",\n",
    "                          'Submit': 'Submit',\n",
    "                          \"__EVENTTARGET\": \"\",\n",
    "                          \"__EVENTARGUMENT\": \"\",\n",
    "                          \"__EVENTVALIDATION\": eventvalidation,\n",
    "                          \"__VIEWSTATE\": viewstate\n",
    "                    })\n",
    "\n",
    "    return r.text\n",
    "\n",
    "\n",
    "\n",
    "data = extract_data(html_page)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337742"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "r = s.get(\"https://www.transtats.bts.gov/Data_Elements.aspx?Data=2\")\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "viewstate = soup.find(id=\"__VIEWSTATE\")['value']\n",
    "eventvalidation = soup.find(id=\"__EVENTVALIDATION\")['value']\n",
    "\n",
    "r = s.post(\"https://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "          data = (\n",
    "                   (\"__EVENTTARGET\", \"\"),\n",
    "                   (\"__EVENTARGUMENT\", \"\"),\n",
    "                   (\"__VIEWSTATE\", viewstate),\n",
    "                   (\"__EVENTVALIDATION\", eventvalidation),\n",
    "                   (\"CarrierList\", \"VX\"),\n",
    "                   (\"AirportList\", \"BOS\"),\n",
    "                   (\"Submit\", \"Submit\")          \n",
    "          ))\n",
    "\n",
    "f = open('data/virgin_and_logan_airport.html', 'w')\n",
    "f.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
